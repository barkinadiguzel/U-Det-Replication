# ğŸ” U-Det-Replication â€” Multi-Scale BiFPN Segmentation

This repository provides a **PyTorch-based replication** of  
**U-Det: A U-Net Enhanced with Bi-FPN for Pulmonary Nodule Segmentation**,  
implemented as a **modular, research-friendly segmentation framework**.

The project translates the paperâ€™s **U-Net backbone, Bi-FPN feature fusion, and progressive decoding**  
into a clean, extendable codebase.

- Enables **high-accuracy nodule segmentation on 2D/3D CT slices** ğŸ«  
- Implements **multi-scale feature fusion via Bi-FPN blocks** âš¡  
- Incorporates **weighted binary cross-entropy for class imbalance** âœ¦  
- Designed for **reproducible and efficient inference pipelines** ğŸœ‚  

**Paper reference:** [U-Det: Multi-Scale BiFPN for Pulmonary Nodule Segmentation â€” Author et al., 2023](https://arxiv.org/abs/2003.09293) ğŸ“„

---

## ğŸ† Overview â€” Multi-Scale Segmentation Pipeline

![U-Det Overview](images/figmix.jpg)

> Pulmonary nodules vary widely in **size, density, and shape**, requiring multi-scale reasoning.  

The network learns a mapping:

$$
f_\theta : \mathbb{R}^{H \times W} \rightarrow \mathbb{R}^{H \times W}
$$

where the output is a **segmentation mask** $\hat{Y}$ for a given CT slice $X$.

The architecture combines **U-Net encodingâ€“decoding** with **Bi-FPN for hierarchical feature fusion**,  
enabling robust detection of both small and large nodules.

---

## ğŸ§  Architectural Principle â€” U-Det

- **Encoder**: Standard U-Net blocks with progressive downsampling  
- **Bi-FPN**: Multi-scale feature fusion across 5 feature levels  
- **Decoder**: Symmetric upsampling with skip connections  
- **Output**: Single-channel mask with sigmoid activation  

Mathematically, for encoder features $[f_1, ..., f_5]$, Bi-FPN produces fused features:

$$
[F_1, ..., F_5] = \text{BiFPN}([f_1, ..., f_5])
$$

and the decoder reconstructs the mask:

$$
\hat{Y} = \text{Decoder}(F_1, ..., F_5)
$$

---

## ğŸ”¬ Loss Function â€” Weighted Binary Cross-Entropy

To handle class imbalance between nodule and background:

$$
\mathcal{L}_{WBCE} = - \frac{1}{N} \sum_i \big( w \cdot y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i) \big)
$$

where $w$ is the **positive class weight**, $y_i$ is the ground-truth, and $\hat{y}_i$ the predicted probability.

---

## ğŸ©» Data Handling

- **Dataset**: LUNA-16 CT slices  
- **Augmentation**: Random flip, rotation, elastic noise  
- **Normalization**: Each slice scaled to $[0,1]$  

This improves **training stability** and **model generalization**.

---

## ğŸ§ª What the Model Learns

- Detect **multi-scale nodules** with varying density ğŸŒ«ï¸  
- Preserve **edge geometry** through skip connections ğŸ€  
- Fuse features **across scales** using Bi-FPN âš¡  
- Suppress false positives from vessels and airway structures ğŸœƒ  

Segmentation becomes a **context-aware multi-scale reasoning task** rather than a simple pixel-wise classification.

---

## ğŸ“¦ Repository Structure

```bash
U-Det-Replication/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ encoders.py           # U-Net encoder blocks
â”‚   â”‚   â”œâ”€â”€ bifpn.py              # Bi-FPN feature fusion
â”‚   â”‚   â”œâ”€â”€ decoder.py            # Decoder blocks
â”‚   â”‚   â””â”€â”€ udet.py               # Full U-Det assembly
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ luna_loader.py        # LUNA16 slice loader
â”‚   â”‚
â”‚   â”œâ”€â”€ augmentation/
â”‚   â”‚   â””â”€â”€ transforms.py         # Flip, rotate, noise, elastic
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ inference_pipeline.py # Model inference â†’ mask
â”‚   â”‚
â”‚   â”œâ”€â”€ loss/
â”‚   â”‚   â””â”€â”€ weighted_bce.py       # Weighted BCE loss
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ metrics.py            # Dice, IoU
â”‚   â”‚   â””â”€â”€ visualization.py      # Slice + mask overlay
â”‚   â”‚
â”‚   â””â”€â”€ config.py                 # Model + training parameters
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---


## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
